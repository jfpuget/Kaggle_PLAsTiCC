{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname='base_006'\n",
    "\n",
    "n_tta = 6\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.optimize import curve_fit\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import logging\n",
    "from tqdm import tqdm_notebook\n",
    "import itertools\n",
    "import pickle as pkl\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rn\n",
    "def init_seeds(seed):\n",
    "\n",
    "    # The below is necessary for starting Numpy generated random numbers\n",
    "    # in a well-defined initial state.\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # The below is necessary for starting core Python generated random numbers\n",
    "    # in a well-defined state.\n",
    "\n",
    "    rn.seed(seed)\n",
    "\n",
    "\n",
    "init_seeds(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregations():\n",
    "    aggs = {\n",
    "        'flux' : ['min', 'max', 'mean', 'std', 'skew'],\n",
    "        'flux_delta' : ['mean', 'median', 'std'],\n",
    "        'flux_err' : ['min', 'max', 'mean', 'median', 'std'],\n",
    "        'detected' : ['mean'],  # ''min', 'max', 'mean', 'median', 'std'],\n",
    "        'flux_ratio_sq' : ['sum'],\n",
    "        'flux_by_flux_ratio_sq' : ['sum'],\n",
    "        'mjd_detected' : ['min', 'max'],\n",
    "        'mjd_detected_std' : ['min', 'max'],\n",
    "        'flux_detected' : ['mean'],  # ''min', 'max', 'mean', 'median', 'std'],\n",
    "        'flux_slope_change' : ['mean'],\n",
    "        'scale':['mean'],\n",
    "        'magnitude':['mean'],\n",
    "    }\n",
    "    \n",
    "    for pb in range(6):\n",
    "        flux_pb = 'flux_%d' % pb\n",
    "        aggs[flux_pb] = ['min', 'max', 'mean', 'median', 'std', 'skew']\n",
    "        flux_delta_pb = 'flux_delta_%d' % pb\n",
    "        aggs[flux_delta_pb] = ['std']\n",
    "        detected_pb = 'detected_%d' % pb\n",
    "        aggs[detected_pb] = ['mean']\n",
    "        flux_pb_detected = 'flux_%d_detected' % pb\n",
    "        aggs[flux_pb_detected] = ['mean']\n",
    "        flux_ratio_sq_pb = 'flux_ratio_sq_%d' % pb\n",
    "        aggs[flux_ratio_sq_pb] = ['sum']\n",
    "        flux_by_flux_ratio_sq_pb = 'flux_by_flux_ratio_sq_%d' % pb\n",
    "        aggs[flux_by_flux_ratio_sq_pb] = ['sum']\n",
    "    return aggs\n",
    "\n",
    "\n",
    "def get_new_columns(aggs):\n",
    "    return [k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n",
    "\n",
    "def apply_kurt(df):\n",
    "    cols = ['flux'] + ['flux_%d' % pb for pb in range(6)]\n",
    "    agg =  df.groupby('object_id')[cols].apply(pd.DataFrame.kurt)\n",
    "    agg.columns = [c+'_kurt' for c in agg.columns]\n",
    "    return agg\n",
    "\n",
    "def apply_kurt_delta(df):\n",
    "    cols = ['flux_delta'] \n",
    "    agg =  df.groupby('object_id')[cols].apply(pd.DataFrame.kurt)\n",
    "    agg.columns = [c+'_kurt' for c in agg.columns]\n",
    "    return agg\n",
    "\n",
    "def add_features_to_agg(df):\n",
    "    df['mjd_detected_diff'] = df['mjd_detected_max'] - df['mjd_detected_min']\n",
    "    del df['mjd_detected_max'], df['mjd_detected_min']\n",
    "    df['mjd_detected_std_diff'] = df['mjd_detected_std_max'] - df['mjd_detected_std_min']\n",
    "    del df['mjd_detected_std_max'], df['mjd_detected_std_min']\n",
    "    df['flux_diff'] = df['flux_max'] - df['flux_min']\n",
    "    df['flux_dif2'] = (df['flux_max'] - df['flux_min']) / df['flux_mean']\n",
    "    df['flux_w_mean'] = df['flux_by_flux_ratio_sq_sum'] / df['flux_ratio_sq_sum']\n",
    "    df['flux_dif3'] = (df['flux_max'] - df['flux_min']) / df['flux_w_mean']\n",
    "    df['flux_detected_ratio'] = df['flux_detected_mean'] / df['flux_mean']\n",
    "    df['flux_delta_mean_ratio'] = df['flux_delta_mean'] / df['flux_mean']\n",
    "    df['flux_delta_std_ratio'] = df['flux_delta_std'] / df['flux_std']\n",
    "    #df['flux_delta_skew_ratio'] = df['flux_delta_skew'] / df['flux_skew']\n",
    "    #del df['flux_delta_skew']\n",
    "    #df['flux_delta_kurt_ratio'] = df['flux_delta_kurt'] / df['flux_kurt']\n",
    "    for pb in range(6):\n",
    "        #df['flux_%d_diff' % pb] = df['flux_%d_max' % pb] - df['flux_%d_min' % pb]\n",
    "        #df['flux_%d_diff_2' % pb] = (df['flux_%d_max' % pb] - df['flux_%d_min' % pb]) / df['flux_%d_mean' % pb]\n",
    "\n",
    "        df['flux_%d_detected_ratio' % pb] = df['flux_%d_detected_mean' % pb] / df['flux_%d_mean' % pb]\n",
    "        df['flux_%d_mean' % pb] /= df.flux_mean\n",
    "        df['flux_%d_detected_mean' % pb] /= df.flux_detected_mean\n",
    "        df['flux_%d_max_ratio' % pb] = df['flux_%d_max' % pb] / df['flux_max']\n",
    "        #df['flux_%d_min_ratio' % pb] = df['flux_%d_min' % pb] / df['flux_min']\n",
    "        #df['flux_delta_%d_std_ratio' % pb] = df['flux_delta_%d_std' % pb] / df['flux_delta_std']\n",
    "        df['flux_delta_%d_std_ratio_2' % pb] = df['flux_delta_%d_std' % pb] / df['flux_std']\n",
    "        #df['flux_%d_std_ratio' % pb] = df['flux_%d_std' % pb] / df['flux_std']\n",
    "        df['flux_%d_w_mean' % pb] = df['flux_by_flux_ratio_sq_%d_sum' % pb] / df['flux_ratio_sq_%d_sum' % pb]\n",
    "        df['flux_%d_dif3'] = (df['flux_%d_max' % pb] - df['flux_%d_min' % pb]) / df['flux_%d_w_mean' % pb]\n",
    "        df['flux_%d_w_mean' % pb] /= df['flux_w_mean']\n",
    "        #df['flux_ratio_sq_%d_sum' % pb] /= df['flux_ratio_sq_sum']\n",
    "        del df['flux_delta_%d_std' % pb], df['flux_by_flux_ratio_sq_%d_sum' % pb]\n",
    "        #del df['flux_ratio_sq_%d_sum' % pb]\n",
    "    del df['flux_by_flux_ratio_sq_sum']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_before_agg(df):\n",
    "    \n",
    "    df['flux_ratio_sq'] = np.power(df['flux'] / df['flux_err'], 2.0)\n",
    "    df['flux_by_flux_ratio_sq'] = df['flux'] * df['flux_ratio_sq']\n",
    "    \n",
    "    df['mjd_detected'] = np.NaN\n",
    "    df.loc[df.detected == 1, 'mjd_detected'] = df.loc[df.detected == 1, 'mjd']\n",
    "    \n",
    "    df['flux_detected'] = np.NaN\n",
    "    df.loc[df.detected == 1, 'flux_detected'] = df.loc[df.detected == 1, 'flux']\n",
    "\n",
    "    df['mjd_detected_std'] = np.NaN\n",
    "    df.loc[df.detected_std == 1, 'mjd_detected_std'] = df.loc[df.detected_std == 1, 'mjd']\n",
    "    \n",
    "    gr = df.groupby(['object_id', 'passband'])\n",
    "    df['flux_prev'] = gr.flux.shift(1)\n",
    "    df['mjd_prev'] = gr.mjd.shift(1)\n",
    "    \n",
    "    df['flux_delta'] = (df.flux - df.flux_prev) \n",
    "    df['flux_delta_abs'] = np.abs(df.flux_delta)\n",
    "\n",
    "    df.loc[df.flux_delta_abs * df.scale < 10, 'flux_delta'] = np.NaN\n",
    "    df.loc[(df.mjd - df.mjd_prev) > 100, 'flux_delta'] = np.NaN\n",
    "    df['flux_slope'] = np.sign(df.flux_delta) \n",
    "                               \n",
    "    df['flux_slope_prev'] = gr.flux_slope.shift(1).fillna('prev')\n",
    "    df['flux_slope_change'] = 1*(df['flux_slope'] != df['flux_slope_prev'])                               \n",
    "    del df['flux_prev'], df['flux_slope_prev'], df['flux_slope'], df['mjd_prev']\n",
    "\n",
    "    for pb in range(6):\n",
    "        filter_p = (df.passband == pb)\n",
    "        \n",
    "        flux_pb = 'flux_%d' % pb\n",
    "        df[flux_pb] = np.NaN\n",
    "        df.loc[filter_p, flux_pb] = df.loc[filter_p, 'flux']\n",
    "\n",
    "        flux_delta_pb = 'flux_delta_%d' % pb\n",
    "        df[flux_delta_pb] = np.NaN\n",
    "        df.loc[filter_p, flux_delta_pb] = df.loc[filter_p, 'flux_delta']\n",
    "        \n",
    "        detected_pb = 'detected_%d' % pb\n",
    "        df[detected_pb] = 0\n",
    "        df.loc[filter_p, detected_pb] = df.loc[filter_p, 'detected']\n",
    "        \n",
    "        flux_pb_detected = 'flux_%d_detected' % pb\n",
    "        df[flux_pb_detected] = np.NaN\n",
    "        df.loc[filter_p, flux_pb_detected] = df.loc[filter_p, 'flux_detected']\n",
    "        \n",
    "        flux_ratio_sq_pb = 'flux_ratio_sq_%d' % pb\n",
    "        df[flux_ratio_sq_pb] = np.NaN\n",
    "        df.loc[filter_p, flux_ratio_sq_pb] = df.loc[filter_p, 'flux_ratio_sq']\n",
    "\n",
    "        flux_by_flux_ratio_sq_pb = 'flux_by_flux_ratio_sq_%d' % pb\n",
    "        df[flux_by_flux_ratio_sq_pb] = np.NaN\n",
    "        df.loc[filter_p, flux_by_flux_ratio_sq_pb] = df.loc[filter_p, 'flux_by_flux_ratio_sq']\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df_, meta_, throughputs=throughputs):\n",
    "    df_ = df_.copy()\n",
    "    \n",
    "    #df_['scale'] = 1\n",
    "    gr = df_.groupby('object_id')\n",
    "    df_['scale'] = gr.flux.transform('max')\n",
    "    df_['magnitude'] = df_['scale'] - gr.flux.transform('min')\n",
    "    \n",
    "    df_.flux /= df_.scale\n",
    "    df_.flux_err /= df_.scale\n",
    "    \n",
    "    gr = df_.groupby(['object_id', 'passband'])  \n",
    "    flux_err_mean = gr.flux_err.transform('mean')\n",
    "    flux_err_std = gr.flux_err.transform('std')\n",
    "    df_ = df_[df_.flux_err <= flux_err_mean + 6*flux_err_std].copy()\n",
    "\n",
    "    gr = df_.groupby(['object_id', 'passband'])  \n",
    "    flux_std = gr.flux.transform('std')\n",
    "    flux_mean = gr.flux.transform('mean')\n",
    "    df_['detected_std'] = df_.detected * (df_.flux > flux_mean + 1*flux_std)\n",
    "    \n",
    "    add_features_before_agg(df_)\n",
    "\n",
    "    aggs = get_aggregations()\n",
    "    new_columns = get_new_columns(aggs)\n",
    "\n",
    "    agg_ = df_.groupby('object_id').agg(aggs)\n",
    "    agg_.columns = new_columns\n",
    "\n",
    "    agg_ = add_features_to_agg(df=agg_)\n",
    "    \n",
    "    agg_kurt = apply_kurt(df_)\n",
    "    \n",
    "    #agg_kurt_delta = apply_kurt_delta(df_)\n",
    "    \n",
    "    agg_ = pd.concat([agg_, agg_kurt], axis=1).reset_index()\n",
    "    #agg_ = agg_.merge(agg_bazin, how='left', on='object_id')\n",
    "\n",
    "    # Merge with meta data\n",
    "    full_df = agg_.merge(\n",
    "        right=meta_,\n",
    "        how='left',\n",
    "        on='object_id'\n",
    "    )\n",
    "    full_df['magnitude_mean'] *= (full_df.hostgal_photoz ** 2)\n",
    "\n",
    "    del agg_\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training time data augmentation\n",
    "\n",
    "def get_tta(train, meta_train, i):\n",
    "    df = train.copy()\n",
    "    init_seeds(i)\n",
    "    if i > 0:\n",
    "        df['flux'] += df['flux_err'] * np.random.randn(*df['flux_err'].shape)\n",
    "    df = add_features(df, meta_train)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>mjd</th>\n",
       "      <th>passband</th>\n",
       "      <th>flux</th>\n",
       "      <th>flux_err</th>\n",
       "      <th>detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>615</td>\n",
       "      <td>59750.4229</td>\n",
       "      <td>2</td>\n",
       "      <td>-544.810303</td>\n",
       "      <td>3.622952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615</td>\n",
       "      <td>59750.4306</td>\n",
       "      <td>1</td>\n",
       "      <td>-816.434326</td>\n",
       "      <td>5.553370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>615</td>\n",
       "      <td>59750.4383</td>\n",
       "      <td>3</td>\n",
       "      <td>-471.385529</td>\n",
       "      <td>3.801213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>59750.4450</td>\n",
       "      <td>4</td>\n",
       "      <td>-388.984985</td>\n",
       "      <td>11.395031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>615</td>\n",
       "      <td>59752.4070</td>\n",
       "      <td>2</td>\n",
       "      <td>-681.858887</td>\n",
       "      <td>4.041204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id         mjd  passband        flux   flux_err  detected\n",
       "0        615  59750.4229         2 -544.810303   3.622952         1\n",
       "1        615  59750.4306         1 -816.434326   5.553370         1\n",
       "2        615  59750.4383         3 -471.385529   3.801213         1\n",
       "3        615  59750.4450         4 -388.984985  11.395031         1\n",
       "4        615  59752.4070         2 -681.858887   4.041204         1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../input/training_set.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>ddf</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>713</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6267</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>745</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1124</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id  ddf  hostgal_photoz  target\n",
       "0        615    1          0.0000      92\n",
       "1        713    1          1.6267      88\n",
       "2        730    1          0.2262      42\n",
       "3        745    1          0.2813      90\n",
       "4       1124    1          0.2415      90"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_cols = ['object_id', 'ddf', 'hostgal_photoz', 'target']\n",
    "meta_train = pd.read_csv('../input/training_set_metadata.csv')[meta_cols]\n",
    "meta_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2dd22bf588423bbceb9b32fecc7621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_tta = 11\n",
    "\n",
    "ttas = [get_tta(train, meta_train, i) for i in tqdm_notebook(range(11))]\n",
    "\n",
    "#for tta in ttas:\n",
    "#    tta.fillna(train_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/ttas_%s.pkl' % fname, 'wb') as file:\n",
    "    pkl.dump(ttas, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work_test(param):\n",
    "    (chunk_id, fname) = param\n",
    "    print('starting worker', chunk_id)\n",
    "    meta_test = pd.read_csv('../input/test_set_metadata.csv')\n",
    "    with open('../input/test_chunk_%d.csv' % chunk_id, 'rb') as file:\n",
    "        test_chunk = pkl.load(file)\n",
    "    full_test = add_features(test_chunk, meta_test)\n",
    "    \n",
    "    with open('../data/full_test_chunk_%s_%d.pkl' % (fname, chunk_id), 'wb') as file:\n",
    "        pkl.dump(full_test, file)\n",
    "    print('ending worker', chunk_id)\n",
    "    return 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting worker 0\n",
      "starting worker 1\n",
      "starting worker 3\n",
      "starting worker 2\n",
      "starting worker 4\n",
      "ending worker 0\n",
      "starting worker 5\n",
      "ending worker 1\n",
      "starting worker 6\n",
      "ending worker 2\n",
      "starting worker 7\n",
      "ending worker 3\n",
      "starting worker 8\n",
      "ending worker 4\n",
      "starting worker 9\n",
      "ending worker 5\n",
      "starting worker 10\n",
      "ending worker 6\n",
      "starting worker 11\n",
      "ending worker 7\n",
      "starting worker 12\n",
      "ending worker 9\n",
      "starting worker 13\n",
      "ending worker 8\n",
      "starting worker 14\n",
      "ending worker 10\n",
      "starting worker 15\n",
      "ending worker 11\n",
      "starting worker 16\n",
      "ending worker 12\n",
      "starting worker 17\n",
      "ending worker 13\n",
      "starting worker 18\n",
      "ending worker 14\n",
      "starting worker 19\n",
      "ending worker 15\n",
      "starting worker 20\n",
      "ending worker 16\n",
      "starting worker 21\n",
      "ending worker 17\n",
      "starting worker 22\n",
      "ending worker 18\n",
      "starting worker 23\n",
      "ending worker 19\n",
      "starting worker 24\n",
      "ending worker 20\n",
      "starting worker 25\n",
      "ending worker 21\n",
      "starting worker 26\n",
      "ending worker 22\n",
      "starting worker 27\n",
      "ending worker 23\n",
      "starting worker 28\n",
      "ending worker 24\n",
      "starting worker 29\n",
      "ending worker 25\n",
      "starting worker 30\n",
      "ending worker 26\n",
      "starting worker 31\n",
      "ending worker 27\n",
      "starting worker 32\n",
      "ending worker 28\n",
      "starting worker 33\n",
      "ending worker 29\n",
      "starting worker 34\n",
      "ending worker 30\n",
      "starting worker 35\n",
      "ending worker 31\n",
      "starting worker 36\n",
      "ending worker 32\n",
      "starting worker 37\n",
      "ending worker 33\n",
      "starting worker 38\n",
      "ending worker 34\n",
      "starting worker 39\n",
      "ending worker 35\n",
      "starting worker 40\n",
      "ending worker 36\n",
      "starting worker 41\n",
      "ending worker 37\n",
      "starting worker 42\n",
      "ending worker 38\n",
      "starting worker 43\n",
      "ending worker 39\n",
      "starting worker 44\n",
      "ending worker 40\n",
      "starting worker 45\n",
      "ending worker 41\n",
      "starting worker 46\n",
      "ending worker 42\n",
      "starting worker 47\n",
      "ending worker 43\n",
      "starting worker 48\n",
      "ending worker 44\n",
      "starting worker 49\n",
      "ending worker 45\n",
      "starting worker 50\n",
      "ending worker 46\n",
      "starting worker 51\n",
      "ending worker 47\n",
      "starting worker 52\n",
      "ending worker 48\n",
      "starting worker 53\n",
      "ending worker 49\n",
      "starting worker 54\n",
      "ending worker 50\n",
      "starting worker 55\n",
      "ending worker 51\n",
      "starting worker 56\n",
      "ending worker 52\n",
      "starting worker 57\n",
      "ending worker 53\n",
      "starting worker 58\n",
      "ending worker 54\n",
      "starting worker 59\n",
      "ending worker 55\n",
      "starting worker 60\n",
      "ending worker 56\n",
      "starting worker 61\n",
      "ending worker 57\n",
      "starting worker 62\n",
      "ending worker 58\n",
      "starting worker 63\n",
      "ending worker 59\n",
      "starting worker 64\n",
      "ending worker 60\n",
      "starting worker 65\n",
      "ending worker 61\n",
      "starting worker 66\n",
      "ending worker 62\n",
      "starting worker 67\n",
      "ending worker 63\n",
      "starting worker 68\n",
      "ending worker 64\n",
      "starting worker 69\n",
      "ending worker 65\n",
      "starting worker 70\n",
      "ending worker 66\n",
      "starting worker 71\n",
      "ending worker 67\n",
      "starting worker 72\n",
      "ending worker 68\n",
      "starting worker 73\n",
      "ending worker 69\n",
      "starting worker 74\n",
      "ending worker 71\n",
      "starting worker 75\n",
      "ending worker 70\n",
      "starting worker 76\n",
      "ending worker 73\n",
      "starting worker 77\n",
      "ending worker 72\n",
      "starting worker 78\n",
      "ending worker 74\n",
      "starting worker 79\n",
      "ending worker 75\n",
      "starting worker 80\n",
      "ending worker 76\n",
      "starting worker 81\n",
      "ending worker 77\n",
      "starting worker 82\n",
      "ending worker 78\n",
      "starting worker 83\n",
      "ending worker 79\n",
      "starting worker 84\n",
      "ending worker 80\n",
      "starting worker 85\n",
      "ending worker 81\n",
      "starting worker 86\n",
      "ending worker 82\n",
      "starting worker 87\n",
      "ending worker 83\n",
      "starting worker 88\n",
      "ending worker 84\n",
      "starting worker 89\n",
      "ending worker 85\n",
      "starting worker 90\n",
      "ending worker 86\n",
      "starting worker 100\n",
      "ending worker 100\n",
      "ending worker 87\n",
      "ending worker 88\n",
      "ending worker 90\n",
      "ending worker 89\n"
     ]
    }
   ],
   "source": [
    "params = [(i, fname) for i in range(91)]\n",
    "params.append((100, fname))\n",
    "\n",
    "if 1: \n",
    "    pool = Pool(processes=5, maxtasksperchild=1)\n",
    "    ls   = pool.map( work_test, params, chunksize=1 )\n",
    "    pool.close()\n",
    "else:\n",
    "    ls = [work_test(param) for param in params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xgb8]",
   "language": "python",
   "name": "conda-env-xgb8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
